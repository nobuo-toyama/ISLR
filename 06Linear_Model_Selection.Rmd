---
title: "Linear Model Selection and Regularization"
author: "nobuo"
date: "2021/4/2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lab 1: Subset Selection Methods

###  Best Subset Selection

```{r}
library(ISLR)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
```
```{r}
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
```
```{r}
library(leaps)
regfit.full <- regsubsets(Salary ~ ., data = Hitters)
summary(regfit.full)
```
```{r}
regfit.full <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19)
reg.summary <- summary(regfit.full)
names(reg.summary)
```
```{r}
reg.summary$rsq
```
```{r}
par(mfrow = c(2, 2))
plot(reg.summary$rss, xlab = "Number of Variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of Variables", ylab = "Adjusted RSq", type = "l")
which.max(reg.summary$adjr2)
points(11, reg.summary$adjr2[11], col = "red", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], col = "red", cex = 2, pch = 20)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6, reg.summary$bic[6], col = "red", cex = 2, pch = 20)
```
 points (11,reg. summary$adjr2[11], col="red",cex=2,pch =20)
```{r}
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
```
###  Forward and Backward Stepwise Selection

 regfit.fwd=regsubsets (Salaryâˆ¼.,data=Hitters , nvmax=19,
method ="forward ")
> summary (regfit.fwd)

```{r}
regfit.fwd <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
regfit.bwd <- regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
summary(regfit.bwd)
```
```{r}
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
```
###  Choosing Among Models Using the Validation Set Approach and Cross-Validation

```{r}
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(Hitters), replace = TRUE)
test <- (!train)
regfit.best <- regsubsets(Salary ~ ., data = Hitters[train, ], nvmax = 19)
```

```{r}
test.mat <- model.matrix(Salary ~ ., data = Hitters[test, ])
val.errors <- rep(NA, 19)
for (i in 1:19) {
  coefi <- coef(regfit.best, id = i)
  pred <- test.mat[, names(coefi)] %*% coefi
  val.errors[i] <- mean((Hitters$Salary[test] - pred)^2)
}
```
We find that the best model is the one that contains seven variables.
```{r}
val.errors
which.min(val.errors)
coef(regfit.best, 7)
```
This was a little tedious, partly because there is no `predict()` method for `regsubsets()`. Since we will be using this function again, we can capture our steps above and write our own predict method.

```{r}
predict.regsubsets <- function(object, newdata, id, ...) {
  form <- formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[, xvars] %*% coefi
}
```
First, we create a vector that allocates each observation to one of $k = 10$ folds, and we create a matrix in which we will store the results.

```{r}
k <- 10
set.seed(1)
folds <- sample(1:k, nrow(Hitters), replace = TRUE)
cv.errors <- matrix(NA, k, 19, dimnames = list(NULL, paste(1:19)))
```
Now we write a for loop that performs cross-validation. 

```{r}
for (j in 1:k) {
  best.fit <- regsubsets(Salary ~ ., data = Hitters[folds!=j, ], nvmax = 19)
  for (i in 1:19) {
    pred <- predict(best.fit, Hitters[folds==j, ], id=i)
    cv.errors[j, i] <- mean((Hitters$Salary[folds==j] - pred)^2)
  }
}
mean.cv.errors <- apply(cv.errors, 2, mean)
mean.cv.errors
```





